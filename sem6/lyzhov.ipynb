{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import alexnet\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from scipy.misc import imresize\n",
    "import torch.cuda\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Задание: выкинуть последний слой из vgg / alexnet и обучить линейную регрессиию на выходах полученных сетей.\n",
    "Например, для mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anet = torchvision.models.alexnet(pretrained = True)\n",
    "fmodel = anet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in fmodel.children():\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU (inplace)\n",
       "  (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU (inplace)\n",
       "  (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU (inplace)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU (inplace)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU (inplace)\n",
       "  (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='~/.datasets')\n",
    "images = mnist['data']\n",
    "images = images.reshape(images.shape[0], 1, 28, 28) # data dims: examples x channels x w x h\n",
    "images = images.astype(np.float32) / 255 # float and normalize\n",
    "labels = mnist['target'].astype(int)\n",
    "np_images_train, np_images_test, np_labels_train, np_labels_test = train_test_split(images, labels, train_size = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(batch):\n",
    "    factor = 8\n",
    "    resized_images = np.empty((batch.shape[0], 1, batch.shape[2] * 8, batch.shape[3] * 8))\n",
    "    for i in xrange(batch.shape[0]):\n",
    "        resized_images[i, 0, :] = imresize(batch[i, 0], size = float(factor))\n",
    "    out_images = np.concatenate([resized_images] * 3, axis = 1)\n",
    "    return out_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(data, labels, iters = None):\n",
    "    if iters is None:\n",
    "        iters = int(np.ceil(float(data.shape[0]) / batchsize))\n",
    "    batchsize = 64\n",
    "    res = np.empty((batchsize * iters, 256 * 6 * 6))\n",
    "    res_labels = labels[:batchsize * iters]\n",
    "    for it in tqdm(xrange(iters)):\n",
    "        orig_batch = data[it * batchsize:(it + 1) * batchsize]\n",
    "        batch = resize(orig_batch)\n",
    "        invar = Variable(torch.from_numpy(batch)).float().cuda()\n",
    "        outvar = fmodel.forward(invar)\n",
    "        flat = outvar.view(outvar.size(0), -1)\n",
    "        flatres = flat.data.cpu().numpy()\n",
    "        res[it * batchsize:(it + 1) * batchsize] = flatres\n",
    "    return res, res_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batchsize = 64\n",
    "# # iters = int(np.ceil(float(np_images_train.shape[0]) / batchsize))\n",
    "# iters = 200 # my system freezes after 250 iterations\n",
    "# # res = np.empty((np_images_train.shape[0], 256 * 6 * 6))\n",
    "# res = np.empty((batchsize * iters, 256 * 6 * 6))\n",
    "# res_labels = np_labels_train[:batchsize * iters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:12<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# for it in tqdm(xrange(iters)):\n",
    "#     orig_batch = np_images_train[it * batchsize:(it + 1) * batchsize]\n",
    "#     batch = resize(orig_batch)\n",
    "#     invar = Variable(torch.from_numpy(batch)).float().cuda()\n",
    "#     outvar = fmodel.forward(invar)\n",
    "#     flat = outvar.view(outvar.size(0), -1)\n",
    "#     flatres = flat.data.cpu().numpy()\n",
    "#     res[it * batchsize:(it + 1) * batchsize] = flatres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "iters = 200\n",
    "res, res_labels = learn(np_images_train, np_labels_train, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('res', res)\n",
    "np.save('labels', res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.load('res.npy')\n",
    "res_labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.fit(res, res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('coef', lin.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "# iters = int(np.ceil(float(np_images_train.shape[0]) / batchsize))\n",
    "iters = 10 # my system freezes after 250 iterations\n",
    "test_res = np.empty((batchsize * iters, 256 * 6 * 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_res, test_res_labels = learn(np_images_test, np_labels_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = lin.predict(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = np.abs(test_pred - test_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.21667351e-01,   6.56489946e-02,   3.49648696e-01,\n",
       "         1.72779428e+00,   3.22825962e-01,   4.95604712e-01,\n",
       "         1.31029449e+00,   3.78463356e-01,   4.52699546e-01,\n",
       "         9.04841639e-01,   5.22935792e+00,   2.65573334e+00,\n",
       "         2.05713091e+00,   4.86902771e-01,   1.29841991e+00,\n",
       "         1.57717807e+00,   1.17124604e+00,   6.65168989e-01,\n",
       "         1.19868264e+00,   1.24911629e+00,   7.52137807e-01,\n",
       "         1.58027875e+00,   2.59414641e-01,   3.39754800e-01,\n",
       "         1.42578161e+00,   3.20700847e-01,   4.21773120e-01,\n",
       "         5.38389632e-01,   8.76520049e-01,   5.14307258e-01,\n",
       "         1.94820709e-01,   3.01659026e+00,   8.90554584e+00,\n",
       "         6.49866499e-02,   3.47280866e-02,   4.32850455e-01,\n",
       "         2.29313225e-01,   1.15484801e-01,   3.06592109e-01,\n",
       "         2.44375731e+00,   3.75470192e-01,   1.53411957e+00,\n",
       "         1.43419186e+00,   1.14382652e+00,   2.48355459e+00,\n",
       "         9.16597901e-01,   1.01969478e+00,   8.64421820e-01,\n",
       "         3.50757145e-01,   3.50834055e+00,   1.40092292e-01,\n",
       "         7.71249056e-01,   3.92023621e-01,   2.60896450e-01,\n",
       "         2.99276838e+07,   8.40427290e-03,   1.78643184e+00,\n",
       "         1.04249312e+00,   2.46680448e-01,   2.10720664e+00,\n",
       "         9.33513663e-01,   1.98179803e-01,   5.86735883e-02,\n",
       "         8.08327252e-02,   5.32069997e-01,   7.40339397e-01,\n",
       "         7.64959565e+00,   5.43279808e-01,   1.62887212e+00,\n",
       "         1.03036348e+00,   1.15047878e+00,   2.64312965e-01,\n",
       "         1.34671975e+08,   7.95087035e-01,   8.76164739e-01,\n",
       "         8.57381399e-01,   5.21149992e-01,   1.21632643e-01,\n",
       "         6.37759687e-01,   2.06151309e+00,   1.43901835e+00,\n",
       "         3.84153211e-01,   1.09226343e+00,   6.98080592e-01,\n",
       "         2.27999956e+00,   8.58860155e-01,   1.57993048e+00,\n",
       "         9.10604158e-01,   4.36949537e-01,   4.99992641e-01,\n",
       "         5.83477007e-01,   1.35826181e+00,   2.03042085e-01,\n",
       "         3.84806899e-01,   2.35424577e+00,   2.42388612e+00,\n",
       "         8.89529272e-01,   3.58689553e-02,   1.20361683e+00,\n",
       "         7.46433650e-01])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
