{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите в нормальном виде результат обучения. А лучше график для accuracy.\n",
    "Еще попробуйте логистическую регрессию.\n",
    "\n",
    "Чтобы не было проблем с памятью, вот такого стоит избегать: Variable(torch.from_numpy(batch)).float().cuda().\n",
    "\n",
    "Создайте одну переменную и меняйте ее содержимое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import alexnet\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from scipy.misc import imresize\n",
    "import torch.cuda\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Задание: выкинуть последний слой из vgg / alexnet и обучить линейную регрессиию на выходах полученных сетей.\n",
    "Например, для mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anet = torchvision.models.alexnet(pretrained = True)\n",
    "fmodel = anet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in fmodel.children():\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU (inplace)\n",
       "  (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU (inplace)\n",
       "  (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU (inplace)\n",
       "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU (inplace)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU (inplace)\n",
       "  (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='~/.datasets')\n",
    "images = mnist['data']\n",
    "images = images.reshape(images.shape[0], 1, 28, 28) # data dims: examples x channels x w x h\n",
    "images = images.astype(np.float32) / 255 # float and normalize\n",
    "labels = mnist['target'].astype(int)\n",
    "np_images_train, np_images_test, np_labels_train, np_labels_test = train_test_split(images, labels, train_size = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(batch):\n",
    "    factor = 8\n",
    "    resized_images = np.empty((batch.shape[0], 1, batch.shape[2] * 8, batch.shape[3] * 8))\n",
    "    for i in xrange(batch.shape[0]):\n",
    "        resized_images[i, 0, :] = imresize(batch[i, 0], size = float(factor))\n",
    "    out_images = np.concatenate([resized_images] * 3, axis = 1)\n",
    "    return out_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(data, labels, iters = None):\n",
    "    if iters is None:\n",
    "        iters = int(np.ceil(float(data.shape[0]) / batchsize))\n",
    "    batchsize = 64\n",
    "    res = np.empty((batchsize * iters, 256 * 6 * 6))\n",
    "    res_labels = labels[:batchsize * iters]\n",
    "    invar = Variable(torch.Tensor(), requires_grad = False)\n",
    "    for it in tqdm(xrange(iters)):\n",
    "        orig_batch = data[it * batchsize:(it + 1) * batchsize]\n",
    "        batch = resize(orig_batch)\n",
    "        ten = torch.from_numpy(batch).float().cuda()\n",
    "        invar.data = ten\n",
    "        outvar = fmodel.forward(invar)\n",
    "        flat = outvar.view(outvar.size(0), -1)\n",
    "        flatres = flat.data.cpu().numpy()\n",
    "        res[it * batchsize:(it + 1) * batchsize] = flatres\n",
    "    return res, res_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(data, labels, iters = None):\n",
    "    if iters is None:\n",
    "        iters = int(np.ceil(float(data.shape[0]) / batchsize))\n",
    "    batchsize = 64\n",
    "    res = np.empty((batchsize * iters, 256 * 6 * 6))\n",
    "    res_labels = labels[:batchsize * iters]\n",
    "    for it in tqdm(xrange(iters)):\n",
    "        orig_batch = data[it * batchsize:(it + 1) * batchsize]\n",
    "        batch = resize(orig_batch)\n",
    "        invar = Variable(torch.from_numpy(batch)).float().cuda()\n",
    "        outvar = fmodel.forward(invar)\n",
    "        flat = outvar.view(outvar.size(0), -1)\n",
    "        flatres = flat.data.cpu().numpy()\n",
    "        res[it * batchsize:(it + 1) * batchsize] = flatres\n",
    "    return res, res_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_iters = 20\n",
    "test_res, test_res_labels = learn(np_images_test, np_labels_test, test_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('res', res)\n",
    "np.save('labels', res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = np.load('res.npy')\n",
    "res_labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logr.fit(res, res_labels)\n",
    "np.save('logr_coef', logr.coef_)\n",
    "np.save('logr_inter', logr.intercept_)\n",
    "np.save('logr_niter', logr.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logr.coef_ = np.load('logr_coef.npy')\n",
    "logr.intercept_ = np.load('logr_inter.npy')\n",
    "logr.n_iter_ = np.load('logr_niter.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logr_pred = logr.predict(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = np.abs(logr_pred - test_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of right answers: 0.9828125\n"
     ]
    }
   ],
   "source": [
    "print('% of right answers: ' + str(float(diff[diff < 0.5].shape[0]) / diff.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin.fit(res, res_labels)\n",
    "np.save('lin_coef', lin.coef_)\n",
    "np.save('lin_inter', lin.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for ind in xrange(5):\n",
    "#     i = 10 - ind * 2\n",
    "#     cur_res = res[:res.shape[0] / i, :]\n",
    "#     cur_res_labels = res_labels[:res_labels.shape[0] / i]\n",
    "#     lin.fit(cur_res, cur_res_labels)\n",
    "#     np.save('coef' + str(i), lin.coef_)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin.coef_ = np.load('lin_coef.npy')\n",
    "lin.intercept_ = np.load('lin_inter.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_pred = lin.predict(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = np.abs(lin_pred - test_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of right answers: 0.19296875\n"
     ]
    }
   ],
   "source": [
    "print('% of right answers: ' + str(float(diff[diff < 0.5].shape[0]) / diff.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487813.08242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression has weird coefficient spikes:\n",
    "print(lin.coef_.mean())\n",
    "np.median(lin.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# buf it still performs slightly better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
