{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Семинар 10: \"Чат-боты\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Лыжов Александр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import string\n",
    "import unicodedata\n",
    "import random\n",
    "from os import listdir\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот семинар посвящен чат-ботам. Вам предстоит реализовать модель Seq2Seq, обученную на субтитрах какого-нибудь фильма.\n",
    "\n",
    "При реализации задания вы можете пользоваться кодом из этого примера: <a href=https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb>реализация машинного перевода на PyTorch</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1: подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте субтитры вашего любимого фильма с сайта https://www.opensubtitles.org/en и поместите их в папку с ноутбуком, назвав файл subtitles.srt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    line = line.strip().decode('utf-8')\n",
    "    if '-->' in line or line.isalnum() or 'subtitles' in line:\n",
    "        line = u''\n",
    "    line = re.sub('<[^>]*>', '', line, flags=re.U)\n",
    "    words = re.findall(r'\\w*', line, flags=re.U)\n",
    "    words = filter(lambda x: x.isalnum(), words)\n",
    "    clean = u' '.join(words)\n",
    "    if clean.isalnum():\n",
    "        clean = u''\n",
    "    clean = clean.lower()\n",
    "    clean = re.sub(r\"([.!?])\", r\" \\1\", clean, flags=re.U)\n",
    "    clean = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", clean, flags=re.U)\n",
    "    clean = clean.strip()\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for filename in listdir('sub'):\n",
    "    lines.extend(open('sub/' + filename).readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = map(clean_line, lines)\n",
    "lines = filter(len, lines)\n",
    "lines = filter(lambda line: len(line.split(' ')) <= 9, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve i just got a weird e mail\n",
      "did you buy us airline tickets\n",
      "aw shoot it was supposed\n",
      "to be a surprise\n",
      "i wanted to thank you for letting\n",
      "me live here all this time\n",
      "so i m treating the family\n",
      "to a vacation\n",
      "steve you re so sweet\n",
      "thanks uncle steve\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print lines[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = Lang()\n",
    "for line in lines:\n",
    "    vocab.addSentence(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(vocab, sentence):\n",
    "    indexes = indexesFromSentence(vocab, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return Variable(torch.LongTensor(indexes).view(-1, 1)).cuda()\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(vocab, pair[0])\n",
    "    target_variable = variableFromSentence(vocab, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = zip(lines[:-1], lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'it s', u'it s disgusting'),\n",
       " (u'it s disgusting', u'steve wasn t real'),\n",
       " (u'steve wasn t real', u'he s a real piece of shit'),\n",
       " (u'he s a real piece of shit', u'this is a big one'),\n",
       " (u'this is a big one', u'somebody probably'),\n",
       " (u'somebody probably', u'tracked it in last week'),\n",
       " (u'tracked it in last week', u'on the bottom of their shoe on'),\n",
       " (u'on the bottom of their shoe on', u'a piece of alien fruit'),\n",
       " (u'a piece of alien fruit', u'get off the high road summer'),\n",
       " (u'get off the high road summer', u'we all got pink eye because you'),\n",
       " (u'we all got pink eye because you', u'won t stop texting on the toilet'),\n",
       " (u'won t stop texting on the toilet', u'but uncle steve taught me'),\n",
       " (u'but uncle steve taught me', u'how to ride a bike'),\n",
       " (u'how to ride a bike', u'no steve put that memory'),\n",
       " (u'no steve put that memory', u'in your brain')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variablesFromPair(vocab, pairs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pairs_backup = pairs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pairs = pairs[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = map(variablesFromPair, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = int(max([tensor[0].size()[0] for tensor in tensors]))\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2: определение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.1 Реализуйте encoder </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size).cuda()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size).cuda()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.hidden_size)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.2 Реализуйте decoder </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.3 Реализуйте forward </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size).cuda()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size).cuda()\n",
    "        self.out = nn.Linear(hidden_size, output_size).cuda()\n",
    "        self.softmax = nn.LogSoftmax().cuda()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.hidden_size)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size).cuda()\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length).cuda()\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size).cuda()\n",
    "        self.dropout = nn.Dropout(self.dropout_p).cuda()\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size).cuda()\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size).cuda()\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.hidden_size)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3: обучение модели\n",
    "\n",
    "<i> 3.1 Обучите модель при помощи SGD </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size)).cuda()\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])).cuda()\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di] # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])).cuda()\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    if percent != 0:\n",
    "        es = s / (percent)\n",
    "    else:\n",
    "        es = 0\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_losses(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # this locator puts ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, n_epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    print_loss_total = 0 # Reset every print_every\n",
    "    plot_loss_total = 0 # Reset every plot_every\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [random.choice(tensors) for i in range(n_epochs)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        training_pair = training_pairs[epoch - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "        loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "        \n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256 # set to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vocab.n_words, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(hidden_size, vocab.n_words, 1, dropout_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 39s (- -4m 20s) (3000 0%) 4.8078\n",
      "7m 22s (- -8m 37s) (6000 0%) 4.6991\n",
      "11m 7s (- -12m 52s) (9000 0%) 4.5920\n",
      "14m 51s (- -15m 8s) (12000 0%) 4.5163\n",
      "18m 37s (- -19m 22s) (15000 0%) 4.4919\n",
      "22m 22s (- -23m 37s) (18000 0%) 4.4164\n",
      "26m 9s (- -27m 50s) (21000 0%) 4.3905\n",
      "29m 53s (- -30m 6s) (24000 0%) 4.2994\n",
      "33m 42s (- -34m 17s) (27000 0%) 4.3254\n",
      "37m 29s (- -38m 30s) (30000 0%) 4.2971\n",
      "41m 15s (- -42m 44s) (33000 0%) 4.2118\n",
      "45m 3s (- -46m 56s) (36000 0%) 4.1706\n",
      "48m 54s (- -49m 5s) (39000 0%) 4.1460\n",
      "52m 41s (- -53m 18s) (42000 0%) 4.1043\n",
      "56m 30s (- -57m 29s) (45000 0%) 4.0779\n",
      "60m 19s (- -61m 40s) (48000 0%) 4.0487\n",
      "64m 7s (- -65m 52s) (51000 0%) 3.9795\n",
      "67m 58s (- -68m 1s) (54000 0%) 3.9945\n",
      "71m 48s (- -72m 11s) (57000 0%) 3.8785\n",
      "75m 40s (- -76m 19s) (60000 0%) 3.8894\n",
      "79m 32s (- -80m 27s) (63000 0%) 3.8233\n",
      "83m 23s (- -84m 36s) (66000 0%) 3.7896\n",
      "87m 15s (- -88m 44s) (69000 0%) 3.7683\n",
      "91m 9s (- -92m 50s) (72000 0%) 3.6963\n",
      "95m 3s (- -96m 56s) (75000 0%) 3.7032\n",
      "98m 55s (- -99m 4s) (78000 0%) 3.6214\n",
      "102m 50s (- -103m 9s) (81000 0%) 3.5721\n",
      "106m 45s (- -107m 14s) (84000 0%) 3.5535\n",
      "110m 40s (- -111m 19s) (87000 0%) 3.4782\n",
      "114m 37s (- -115m 22s) (90000 0%) 3.4891\n",
      "118m 31s (- -119m 28s) (93000 0%) 3.4197\n",
      "122m 26s (- -123m 33s) (96000 0%) 3.3955\n",
      "126m 22s (- -127m 37s) (99000 0%) 3.3335\n",
      "130m 21s (- -131m 38s) (102000 0%) 3.3031\n",
      "134m 15s (- -135m 44s) (105000 0%) 3.2556\n",
      "138m 12s (- -139m 47s) (108000 0%) 3.2031\n",
      "142m 11s (- -143m 48s) (111000 0%) 3.2065\n",
      "146m 7s (- -147m 52s) (114000 0%) 3.1685\n",
      "150m 3s (- -151m 56s) (117000 0%) 3.1037\n",
      "154m 1s (- -155m 58s) (120000 0%) 3.0652\n",
      "158m 0s (- -159m 59s) (123000 0%) 3.1244\n",
      "162m 1s (- -163m 58s) (126000 0%) 3.0505\n",
      "165m 59s (- -166m 0s) (129000 0%) 3.0193\n",
      "169m 58s (- -170m 1s) (132000 0%) 3.0558\n",
      "173m 57s (- -174m 2s) (135000 0%) 2.9837\n",
      "177m 58s (- -178m 1s) (138000 0%) 2.8564\n",
      "181m 58s (- -182m 1s) (141000 0%) 2.9237\n",
      "185m 58s (- -186m 1s) (144000 0%) 2.8714\n",
      "190m 0s (- -191m 59s) (147000 0%) 2.8200\n",
      "194m 0s (- 0m 0s) (150000 100%) 2.8417\n"
     ]
    }
   ],
   "source": [
    "losses = trainEpochs(encoder, decoder, 150000, print_every = 3000, plot_every=3000) # 75000 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1aa9e39610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ab3cdce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(encoder.state_dict(), 'encoder_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(decoder.state_dict(), 'decoder_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('encoder_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder.load_state_dict(torch.load('decoder_dict'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.4 Реализуйте evaluate (на каждой итерации выбирайте наиболее вероятное слово)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4: оценивание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 4.1 Продемонстрируйте ответы модели на различные предложения </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(vocab, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size)).cuda()\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])).cuda() # SOS\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden,\n",
    "                                                                    encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(vocab.index2word[ni])\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]])).cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('>', u'we gotta be careful')\n",
      "('=', u'i lost the chance')\n",
      "('<', u'i lost the <EOS>')\n",
      "\n",
      "('>', u'a very satisfying project for')\n",
      "('=', u'people of all ages')\n",
      "('<', u'people of all ages <EOS>')\n",
      "\n",
      "('>', u'be less powerful')\n",
      "('=', u'never gonna happen though')\n",
      "('<', u'and i <EOS>')\n",
      "\n",
      "('>', u'out of the way morty')\n",
      "('=', u'morty that s one of')\n",
      "('<', u'you hey the the <EOS>')\n",
      "\n",
      "('>', u'morty jr smoking')\n",
      "('=', u'that is not okay')\n",
      "('<', u'that is a <EOS>')\n",
      "\n",
      "('>', u'infinite time lines')\n",
      "('=', u'we re not on any')\n",
      "('<', u'through me <EOS>')\n",
      "\n",
      "('>', u'plan your route accordingly')\n",
      "('=', u'and expect delays')\n",
      "('<', u'and re re <EOS>')\n",
      "\n",
      "('>', u'how this place works')\n",
      "('=', u'is there any way we could')\n",
      "('<', u'there is there any way we could <EOS>')\n",
      "\n",
      "('>', u'we were dead')\n",
      "('=', u'so we came here and')\n",
      "('<', u'no i <EOS>')\n",
      "\n",
      "('>', u'fresh start morty')\n",
      "('=', u'create a whole fresh start')\n",
      "('<', u'a whole a whole <EOS>')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'hey', u'you', u'know', '<EOS>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'hey morty')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'there', u'are', u'are', u'coming', u'and', u'they', '<EOS>']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'there s more')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i', u'm', u'taming', u'the', u'council', '<EOS>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'time s up')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
